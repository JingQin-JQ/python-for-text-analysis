{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In block 3, we will start interacting with the world outside of our neat Notebooks, through working with files and importing external modules. While this is quite cool, it brings new types of errors that might occur. These errors might not be logical errors in your program, but rather caused by circumstances in your system. For example, you are trying to write a file to a directory that does not exist. Or, you are trying to use an external library that is not installed in your computer.\n",
    "\n",
    "The purpose of this Notebook is to get you set up for block 3 and remove/minimize such errors in case they appear on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation\n",
    "\n",
    "We will use several existing libraries in this block. Luckily, these are standard libraries and are conveniently included in the Python and Anaconda installations. The only module that might cause us problems is the Natural Language ToolKit (NLTK), which has many specific sub-libraries, and some of them might not come as part of the Anaconda installation. So let's check this to be sure.\n",
    "\n",
    "First, we `import` NLTK (we will learn more about the import command in this block, though it is quite intuitive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk # include NLTK in your program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful?! If yes, we can now use various standard text processing functions in NLTK. Let's now check if the NLTK functions we are interested in exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"This example sentence is used for illustrating some basic NLP tasks. Language is awesome!\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "# Sentence splitting\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# POS tagging\n",
    "tagged_tokens = nltk.pos_tag(tokens)\n",
    "\n",
    "# Lemmatization\n",
    "lmtzr = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "lemma=lmtzr.lemmatize(tokens[1], 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the assignment, we will use the VADER tool. Let's confirm that we have that one installed too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingqin/venv3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "# Import the sentiment analyzer class.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# NOTE: this will produce a warning, but you can safely ignore it.\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might produce a warning, but you can safely ignore that. If there is an error, ask for help.\n",
    "\n",
    "No error? Then NLTK is running smoothly on your machine. Way to go ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Directories/folders\n",
    "\n",
    "Problems with writing in non-existing directories, or reading non-existing files, or accessing directories that we are not permitted to access, are common and usually easy to fix. Let's make sure that the directories we need for this block exist on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "\n",
    "locations_to_test = ('../Data', '../Data/Charlie/charlie.txt', '../Data/Dreams/', \n",
    "                     '../Data/baby_names/names_by_state', '../Data/Debate/debate.csv', '../Data/LCohen/')\n",
    "\n",
    "for location in locations_to_test:\n",
    "    assert path.exists(location), f\"{location} does not exist on your machine!\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's make sure that the needed folders are not empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir as ls\n",
    "\n",
    "non_empty_dirs = ('../Data', '../Data/Dreams/', '../Data/baby_names/names_by_state/', '../Data/LCohen/')\n",
    "for directory in non_empty_dirs:\n",
    "    assert ls(directory), f\"{directory} is empty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have encountered no error until here, then you are all set!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
